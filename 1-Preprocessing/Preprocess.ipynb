{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import ISRIStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using hand made stemmer\n",
    "def process_tweet_1(tweet):\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', tweet)\n",
    "    # # removal\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # Remove punctuation\n",
    "    tweet = re.sub(r'[\\u060C\\u061B\\u061F]', '', tweet)\n",
    "    # Remove diacritic\n",
    "    tweet = re.sub(r'[\\u064B-\\u0652]', '', tweet)\n",
    "    # yaaa with yaaa with points\n",
    "    tweet = re.sub(r'\\u0649', '\\u064A', tweet)\n",
    "    # Remove tatweel\n",
    "    tweet = re.sub(r'\\u0640', '', tweet)\n",
    "    # Remove alef with madda\n",
    "    tweet = re.sub(r'\\u0622', '\\u0627', tweet)\n",
    "    # Remove alef with hamza above\n",
    "    tweet = re.sub(r'\\u0623', '\\u0627', tweet)\n",
    "    # Remove alef with hamza below\n",
    "    tweet = re.sub(r'\\u0625', '\\u0627', tweet)\n",
    "    # Remove alef maksura\n",
    "    tweet = re.sub(r'\\u0649', '\\u064a', tweet)\n",
    "    # taa marbota to heh\n",
    "    tweet = re.sub(r'\\u0629', '\\u0647', tweet)\n",
    "    # Remove non-arabic characters\n",
    "    tweet = re.sub(r'[^\\u0621-\\u064A]', ' ', tweet)\n",
    "    # Remove extra spaces\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('arabic')]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the nltk stemmer\n",
    "def process_tweet_2(tweet):\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('arabic')]\n",
    "\n",
    "    stemmer = ISRIStemmer()\n",
    "    filtered_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    filtered_tokens = [re.sub(r'[^\\u0621-\\u064A]', '', token) for token in filtered_tokens]\n",
    "    filtered_tokens = [token for token in filtered_tokens if token != '']\n",
    "\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('../Dataset/train.csv')\n",
    "training_set.category = pd.Categorical(training_set.category)\n",
    "training_set['category'] = training_set.category.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❌فيديو التغريدة المقتبسة فيه انتقاص من  العامة بوجوب أخذ الدواء/التطعيم دون سؤال<LF><LF>✅من حق المراجع/كل شخص ان يعرف كل دواء/تطعيم، لماذا يأخذه، كيف يعمل و ماهي مضاعفاته و ماهي عواقب عدم أخذ الدواء/التطعيم<LF><LF>✅التثقيف الدوائي عنصر مهم لالتزام الناس بالأدوية/التطعيمات وتحسين الصحة https://t.co/r4imVyw8h0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'فيديو التغريده المقتبسه انتقاص العامه بوجوب اخذ الدواء التطعيم سؤال حق المراجع شخص ان يعرف دواء تطعيم لماذا ياخذه يعمل ماهي مضاعفاته ماهي عواقب عدم اخذ الدواء التطعيم التثقيف الدوائي عنصر مهم لالتزام الناس بالادويه التطعيمات وتحسين الصحه'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'فيديو غرد قبس نقص عمة وجب دواءالتطعيم سؤل من حق مراجعكل شخص ان عرف دواءتطعيم لمذ أخذه عمل اهي مضاعفاته اهي عقب عدم دواءالتطعيم التثقيف دئي عنصر مهم لزم ناس ادويةالتطعيم تحس صحة'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = len(training_set['text'])\n",
    "index = np.random.randint(0, length)\n",
    "test = training_set['text'][index]\n",
    "display(test)\n",
    "display(' '.join(process_tweet_1(test)))\n",
    "display(' '.join(process_tweet_2(test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
