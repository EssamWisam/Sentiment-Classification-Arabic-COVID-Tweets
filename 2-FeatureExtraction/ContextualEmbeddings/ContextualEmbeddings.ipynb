{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_preprocess(tweet):\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', tweet)\n",
    "    tweet = re.sub(r'[\\u064B-\\u0652]', '', tweet)\n",
    "    tweet = re.sub(r'[^\\u0621-\\u064A\\u0660-\\u0669 ]+', ' ', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_embeddings(tweets):\n",
    "  base_model_name = 'moha/arabert_c19'\n",
    "  tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "  base_model = AutoModel.from_pretrained(base_model_name).to(device)\n",
    "  base_model.eval()\n",
    "  for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "  tokens = [tokenizer(tweet,\n",
    "                padding='max_length',\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\") for tweet in tweets\n",
    "  ]\n",
    "\n",
    "  embeddings = [(base_model(input_ids=token['input_ids'].to(device),\n",
    "                            attention_mask=token['attention_mask'].to(device),\n",
    "                            return_dict=False)[1]).detach().cpu()\n",
    "                for token in tqdm(tokens)]\n",
    "\n",
    "  return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Contextual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d10e796c8de4a8ca73ef62cc573aad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/420 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072d698384d545bba6c4bea9f2b9b1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88ec390977f425f8cd01b326f028e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/743k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa048f10c9c44eeb8a50c6b2a073680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e0887647e641dbb5bc98337be90c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/516M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at moha/arabert_c19 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at moha/arabert_c19 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 17%|█▋        | 1214/6988 [52:33<5:48:52,  3.63s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m [contextual_preprocess(tweet) \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m x[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m [contextual_preprocess(tweet) \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m X[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m contextual_embeddings(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X \u001b[39m=\u001b[39m contextual_embeddings(X)\n",
      "\u001b[1;32m/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb Cell 9\u001b[0m in \u001b[0;36mcontextual_embeddings\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   param\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tokens \u001b[39m=\u001b[39m [tokenizer(tweet,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m               padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m               max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m               truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m               return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m ]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m embeddings \u001b[39m=\u001b[39m [(base_model(input_ids\u001b[39m=\u001b[39mtoken[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                           attention_mask\u001b[39m=\u001b[39mtoken[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                           return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m               \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tqdm(tokens)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;32m/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb Cell 9\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   param\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tokens \u001b[39m=\u001b[39m [tokenizer(tweet,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m               padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m               max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m               truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m               return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m ]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m embeddings \u001b[39m=\u001b[39m [(base_model(input_ids\u001b[39m=\u001b[39;49mtoken[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                           attention_mask\u001b[39m=\u001b[39;49mtoken[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                           return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m               \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tqdm(tokens)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/NLP-Project/2-FeatureExtraction/ContextualEmbeddings/ContextualEmbeddings.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1018\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1009\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1011\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1012\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1013\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1017\u001b[0m )\n\u001b[0;32m-> 1018\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1019\u001b[0m     embedding_output,\n\u001b[1;32m   1020\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1021\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1022\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1023\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1024\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1025\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1026\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1027\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1028\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1029\u001b[0m )\n\u001b[1;32m   1030\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1031\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    598\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    599\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    600\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    608\u001b[0m         hidden_states,\n\u001b[1;32m    609\u001b[0m         attention_mask,\n\u001b[1;32m    610\u001b[0m         layer_head_mask,\n\u001b[1;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    613\u001b[0m         past_key_value,\n\u001b[1;32m    614\u001b[0m         output_attentions,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:535\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    532\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    533\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 535\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    536\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    537\u001b[0m )\n\u001b[1;32m    538\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    540\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/pytorch_utils.py:243\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:547\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 547\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    548\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    549\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:447\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 447\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    448\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py:93\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1692\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m     ret \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39maddmm(bias, \u001b[39minput\u001b[39m, weight\u001b[39m.\u001b[39mt())\n\u001b[1;32m   1691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mmatmul(weight\u001b[39m.\u001b[39;49mt())\n\u001b[1;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1694\u001b[0m         output \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bias\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DIR = lambda x : f'../../Dataset/SavedFeatures/CONTEXT/{x}.npy'\n",
    "D_DIR = lambda x : f'../../Dataset/{x}.npy'\n",
    "\n",
    "Preprocessing = {\"approach\": \"contextual\"}\n",
    "Features = {\"approach\": \"contextual\"}\n",
    "\n",
    "y1 = np.load(D_DIR('y1'), allow_pickle=True)\n",
    "y2 = np.load(D_DIR('y2'), allow_pickle=True)\n",
    "Y1 = np.load(D_DIR('Y1_test'), allow_pickle=True)\n",
    "Y2 = np.load(D_DIR('Y2_test'), allow_pickle=True)\n",
    "\n",
    "saved = False\n",
    "if saved:\n",
    "    x = np.load(DIR('x'), allow_pickle=True)\n",
    "    X = np.load(DIR('X_test'), allow_pickle=True)\n",
    "    \n",
    "else:\n",
    "   x = pd.read_csv('../../Dataset/train.csv')\n",
    "   X = pd.read_csv('../../Dataset/dev.csv')\n",
    "   x = [contextual_preprocess(tweet) for tweet in x['text']]\n",
    "   X = [contextual_preprocess(tweet) for tweet in X['text']]\n",
    "   x = contextual_embeddings(x)\n",
    "   X = contextual_embeddings(X)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
