{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_preprocess(tweet):\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', tweet)\n",
    "    tweet = re.sub(r'[\\u064B-\\u0652]', '', tweet)\n",
    "    tweet = re.sub(r'[^\\u0621-\\u064A\\u0660-\\u0669 ]+', ' ', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_embeddings(tweets):\n",
    "  base_model_name = 'moha/arabert_c19'\n",
    "  tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "  base_model = AutoModel.from_pretrained(base_model_name).to(device)\n",
    "  base_model.eval()\n",
    "  for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "  tokens = [\n",
    "      tokenizer(tweet,\n",
    "                padding='max_length',\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\") for tweet in tweets\n",
    "  ]\n",
    "\n",
    "  embeddings = [(base_model(input_ids=token['input_ids'].to(device),\n",
    "                            attention_mask=token['attention_mask'].to(device),\n",
    "                            return_dict=False)[1]).detach().cpu()\n",
    "                for token in tqdm(tokens)]\n",
    "\n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../Dataset/train.csv')\n",
    "valid_data = pd.read_csv('../../Dataset/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_tweets = [contextual_preprocess(tweet) for tweet in train_data['text']]\n",
    "processed_valid_tweets = [contextual_preprocess(tweet) for tweet in valid_data['text']]\n",
    "\n",
    "train_contextual_embeddings = contextual_embeddings(processed_train_tweets)\n",
    "valid_contextual_embeddings = contextual_embeddings(processed_valid_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list_2 = train_data.category.unique()\n",
    "labels_2 = {k: v for v, k in enumerate(labels_list_2)}\n",
    "train_labels_2 = [labels_2[label] for label in train_data['category']]\n",
    "valid_labels_2 = [labels_2[label] for label in valid_data['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list_1 = train_data.stance.unique()\n",
    "labels_1 = {k: v for v, k in enumerate(labels_list_1)}\n",
    "train_labels_1 = [labels_1[label] for label in train_data['stance']]\n",
    "valid_labels_1 = [labels_1[label] for label in valid_data['stance']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
