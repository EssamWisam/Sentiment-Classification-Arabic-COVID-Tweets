{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "import csv\n",
    "with io.capture_output() as captured:  \n",
    "   %run ../../2-FeatureExtraction/OneHot/OneHot.ipynb import x, y1, y2, X, Y1, Y2, vocabulary, Preprocessing, Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(x), torch.from_numpy(y2))\n",
    "valid_data = TensorDataset(torch.from_numpy(X), torch.from_numpy(Y2))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim,  hidden_dim, output_dim,  num_layers, drop_prob=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Network Dimensions\n",
    "        self.vocab_size, self.hidden_dim, self.output_dim  = vocab_size, hidden_dim, output_dim\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Drop out layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "    \n",
    "        # Output Layer\n",
    "        self.output = nn.Linear(self.hidden_dim, output_dim)      # Or make it linear and use Sofrmax (in loss)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        embeds = self.embedding(x)                                          # B * Seq_Len * embedding_dim\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embeds)                                     # B * Seq_Len * hidden_dim\n",
    "        \n",
    "        lstm_out =  lstm_out[:, -1, :]                                      # B * hidden_dim\n",
    "\n",
    "        drop_out = self.dropout(lstm_out)                                   # B * hidden_dim\n",
    "\n",
    "        \n",
    "        out = self.output(drop_out)                                         # B * output_dim\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceModel(\n",
      "  (embedding): Embedding(17616, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "vocab_size = len(vocabulary)\n",
    "embedding_dim = 200\n",
    "output_dim = 10\n",
    "hidden_dim = 256\n",
    "drop_prob = 0.5\n",
    "lr=0.001\n",
    "clip = 5\n",
    "epochs = 5\n",
    "WeightedLoss = True\n",
    "\n",
    "ModelInfo = {\n",
    "   \"Model\": \"LSTM-2\",\n",
    "   \"batch_size\": batch_size,\n",
    "   \"Number of Layers\": num_layers,\n",
    "   \"Embedding Dimension\": embedding_dim,\n",
    "   \"Hidden Dimension\": hidden_dim,\n",
    "   \"Dropout Prob\": drop_prob,\n",
    "   \"Learning Rate\": lr,\n",
    "   \"Gradient Clip\": clip,\n",
    "   \"Number of Epochs\": epochs,\n",
    "   \"Weighted Loss\": WeightedLoss\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "model = SequenceModel(vocab_size, embedding_dim,  hidden_dim, output_dim,  num_layers).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training & Validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "if WeightedLoss:\n",
    "    w = torch.tensor(np.load(\"../../Dataset/w2.npy\").astype(np.float32)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=w).to(device)\n",
    "else:\n",
    "      criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:26<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 22/55 [00:31<00:45,  1.37s/it]"
     ]
    }
   ],
   "source": [
    "epoch_tr_loss, epoch_vl_loss = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)   \n",
    "        \n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "    val_losses = []\n",
    "    for inputs, labels in valid_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs)\n",
    "            val_loss = criterion(output, labels)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    epoch_tr_loss.append(np.mean(train_losses))\n",
    "    epoch_vl_loss.append(np.mean(val_losses))\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(25*'==')\n",
    "    if epoch == epochs-1 or epoch_vl_loss[-1] > epoch_tr_loss[-1]:\n",
    "        F1 = f1_score(labels.cpu().numpy(), output.argmax(1).cpu().numpy(), average='macro')\n",
    "        Report = classification_report(labels.cpu().numpy(), output.argmax(1).cpu().numpy(), output_dict=True)\n",
    "        print(\"Done\")\n",
    "        print(classification_report(labels.cpu().numpy(), output.argmax(1).cpu().numpy()))\n",
    "        print(\"Macro F1 Score: \", F1)         \n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Run Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs.csv', 'a') as f:  \n",
    "      run_info = {**Preprocessing, **Features, **ModelInfo, \"acc\":Report[\"accuracy\"],\"BF1\": Report[\"macro avg\"][\"f1-score\"], \"WF1\": Report[\"weighted avg\"][\"f1-score\"] }\n",
    "      w = csv.DictWriter(f, run_info.keys())\n",
    "      w.writeheader()\n",
    "      w.writerow(run_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYPUlEQVR4nO3de5BV5Znv8e8jdOwgogmN44UM6JloItfGFo0XxEvlIhwvBEupiUqMpiQ1SYzRSGIinGSsmoyU4RCNKWPUmDjppJLASRQ1ATVgZUYDiHfMqMEKo1GEkotCFOc5f/SGabCbvu2mm5fvp2pVr73etd71vOyqH2+vvfbqyEwkSeXaq6cLkCR1L4Nekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6g1x4tIlZGxGk9XYfUnQx6SSqcQS/tICL2jojZEfFSZZkdEXtX2uoi4q6IeD0i1kbE4ojYq9J2VUT8V0RsiIhnI+LUnh2J1KRvTxcg9UJXA8cCo4EE/h/wdeAbwJeBVcCgyr7HAhkRRwD/BBydmS9FxFCgz64tW2qZM3rp3f4R+GZmvpqZq4H/A5xfaXsbOAgYkplvZ+bibHpg1DvA3sCREVGTmSsz8/keqV7agUEvvdvBwIvNXr9Y2QZwHfAc8NuIeCEipgNk5nPAZcBM4NWIaIyIg5F6AYNeereXgCHNXv99ZRuZuSEzv5yZhwH/G7h867X4zPy3zDyhcmwC3961ZUstM+glqImI2q0L8FPg6xExKCLqgGuAnwBExMSI+IeICGA9TZds3omIIyLilMqHtpuBTZU2qccZ9BLMpymYty61wBLgceAJYBnwz5V9PwgsADYC/w58LzMfpOn6/L8ArwF/BQ4AvrbLRiDtRPiHRySpbM7oJalwBr0kFc6gl6TCGfSSVLhe+QiEurq6HDp0aE+XIUm7jaVLl76WmYNaauuVQT906FCWLFnS02VI0m4jIl5src1LN5JUOINekgpn0EtS4XrlNXpJu9bbb7/NqlWr2Lx5c0+XojbU1tYyePBgampq2n2MQS+JVatWse+++zJ06FCantem3igzWbNmDatWreLQQw9t93FeupHE5s2bGThwoCHfy0UEAwcO7PBvXga9JABDfjfRmffJoJekwhn0knrcmjVrGD16NKNHj+bAAw/kkEMO2fb6rbfe2umxS5Ys4Qtf+EKHzjd06FBee+21rpS8W/HDWEk9buDAgSxfvhyAmTNn0r9/f6644opt7Vu2bKFv35bjqqGhgYaGhl1R5m7LGb2kXmnq1KlcfvnlnHzyyVx11VU88sgjHHfccdTX13Pcccfx7LPPAvDggw8yceJEoOk/iYsuuojx48dz2GGHMWfOnDbPc/311zN8+HCGDx/O7NmzAXjjjTeYMGECo0aNYvjw4fzsZz8DYPr06Rx55JGMHDlyu/+Iejtn9JK2d9llUJldV83o0VAJ0Y7405/+xIIFC+jTpw/r169n0aJF9O3blwULFvC1r32NX/7yl+86ZsWKFTzwwANs2LCBI444gmnTprV6z/nSpUu57bbbePjhh8lMjjnmGE466SReeOEFDj74YO6++24A1q1bx9q1a5k7dy4rVqwgInj99dc7PJ6e4oxeUq91zjnn0KdPH6ApbM855xyGDx/Ol770JZ566qkWj5kwYQJ77703dXV1HHDAAbzyyiut9v/QQw9x9tlns88++9C/f38mTZrE4sWLGTFiBAsWLOCqq65i8eLF7LfffgwYMIDa2louvvhifvWrX9GvX79uGXN3cEYvaXudmHl3l3322Wfb+je+8Q1OPvlk5s6dy8qVKxk/fnyLx+y9997b1vv06cOWLVta7b+1v5l9+OGHs3TpUubPn89Xv/pVPvrRj3LNNdfwyCOPsHDhQhobG7nhhhu4//77OzewXcwZvaTdwrp16zjkkEMAuP3226vS57hx45g3bx5vvvkmb7zxBnPnzuXEE0/kpZdeol+/fnzqU5/iiiuuYNmyZWzcuJF169Zx+umnM3v27G0fHu8OnNFL2i185Stf4cILL+T666/nlFNOqUqfY8aMYerUqYwdOxaAiy++mPr6eu677z6uvPJK9tprL2pqarjpppvYsGEDZ555Jps3byYz+c53vlOVGnaFaO1Xl57U0NCQ/uERadd55pln+PCHP9zTZaidWnq/ImJpZrZ4n6mXbiSpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJPW78+PHcd999222bPXs2n/vc53Z6zNbbsE8//fQWnz0zc+ZMZs2atdNzz5s3j6effnrb62uuuYYFCxZ0oPqWNX/YWk8z6CX1uClTptDY2LjdtsbGRqZMmdKu4+fPn8/+++/fqXPvGPTf/OY3Oe200zrVV29l0EvqcZMnT+auu+7ib3/7GwArV67kpZde4oQTTmDatGk0NDQwbNgwZsyY0eLxzf+QyLXXXssRRxzBaaedtu1RxgA/+MEPOProoxk1ahSf/OQnefPNN/nDH/7Ar3/9a6688kpGjx7N888/z9SpU/nFL34BwMKFC6mvr2fEiBFcdNFF2+obOnQoM2bMYMyYMYwYMYIVK1bsdHxr167lrLPOYuTIkRx77LE8/vjjAPz+97/f9gdW6uvr2bBhAy+//DLjxo1j9OjRDB8+nMWLF3ftHxcfgSBpBz3xlOKBAwcyduxY7r33Xs4880waGxs599xziQiuvfZa3v/+9/POO+9w6qmn8vjjjzNy5MgW+1m6dCmNjY08+uijbNmyhTFjxnDUUUcBMGnSJC655BIAvv71r/PDH/6Qz3/+85xxxhlMnDiRyZMnb9fX5s2bmTp1KgsXLuTwww/nggsu4KabbuKyyy4DoK6ujmXLlvG9732PWbNmccstt7Q6vhkzZlBfX8+8efO4//77ueCCC1i+fDmzZs3ixhtv5Pjjj2fjxo3U1tZy880387GPfYyrr76ad955hzfffLPd/86tcUYvqVdofvmm+WWbn//854wZM4b6+nqeeuqp7S6z7Gjx4sWcffbZ9OvXjwEDBnDGGWdsa3vyySc58cQTGTFiBHfeeWerjzne6tlnn+XQQw/l8MMPB+DCCy9k0aJF29onTZoEwFFHHcXKlSt32tdDDz3E+eefD8App5zCmjVrWLduHccffzyXX345c+bM4fXXX6dv374cffTR3HbbbcycOZMnnniCfffdd6d9t4czeknb6amnFJ911llcfvnlLFu2jE2bNjFmzBj+/Oc/M2vWLP74xz/yvve9j6lTp7J58+ad9hMRLW6fOnUq8+bNY9SoUdx+++08+OCDO+2nreeAbX0ccluPQm6tr4hg+vTpTJgwgfnz53PssceyYMECxo0bx6JFi7j77rs5//zzufLKK7ngggt22n9bnNFL6hX69+/P+PHjueiii7bN5tevX88+++zDfvvtxyuvvMI999yz0z7GjRvH3Llz2bRpExs2bOA3v/nNtrYNGzZw0EEH8fbbb3PnnXdu277vvvuyYcOGd/X1oQ99iJUrV/Lcc88B8OMf/5iTTjqpU2MbN27ctnM++OCD1NXVMWDAAJ5//nlGjBjBVVddRUNDAytWrODFF1/kgAMO4JJLLuEzn/kMy5Yt69Q5m3NGL6nXmDJlCpMmTdp2CWfUqFHU19czbNgwDjvsMI4//vidHj9mzBjOPfdcRo8ezZAhQzjxxBO3tX3rW9/imGOOYciQIYwYMWJbuJ933nlccsklzJkzZ9uHsAC1tbXcdtttnHPOOWzZsoWjjz6aSy+9tFPjmjlzJp/+9KcZOXIk/fr140c/+hHQdAvpAw88QJ8+fTjyyCP5xCc+QWNjI9dddx01NTX079+fO+64o1PnbM7HFEvyMcW7GR9TLEnajkEvSYUz6CUBbd9lot6hM++TQS+J2tpa1qxZY9j3cpnJmjVrqK2t7dBx3nUjicGDB7Nq1SpWr17d06WoDbW1tQwePLhDxxj0kqipqeHQQw/t6TLUTbx0I0mFazPoI+LWiHg1Ip5spX18RKyLiOWV5ZpmbftHxC8iYkVEPBMRH6lm8ZKktrXn0s3twA3Azr6etTgzW3rC/v8F7s3MyRHxHqBfx0uUJHVFmzP6zFwErO1oxxExABgH/LDSz1uZ+XpH+5EkdU21rtF/JCIei4h7ImJYZdthwGrgtoh4NCJuiYh9WusgIj4bEUsiYomf/EtS9VQj6JcBQzJzFPBdYF5le19gDHBTZtYDbwDTW+skM2/OzIbMbBg0aFAVypIkQRWCPjPXZ+bGyvp8oCYi6oBVwKrMfLiy6y9oCn5J0i7U5aCPiAOj8qT/iBhb6XNNZv4V+EtEHFHZ9VSg9T8NI0nqFm3edRMRPwXGA3URsQqYAdQAZOb3gcnAtIjYAmwCzsv/+R7154E7K3fcvAB8uuojkCTtVJtBn5lT2mi/gabbL1tqWw60+HxkSdKu4TdjJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klS4NoM+Im6NiFcj4slW2sdHxLqIWF5ZrtmhvU9EPBoRd1WraElS+/Vtxz63AzcAd+xkn8WZObGVti8CzwADOlaaJKka2pzRZ+YiYG1nOo+IwcAE4JbOHC9J6rpqXaP/SEQ8FhH3RMSwZttnA18B/rutDiLisxGxJCKWrF69ukplSZKqEfTLgCGZOQr4LjAPICImAq9m5tL2dJKZN2dmQ2Y2DBo0qAplSZKgCkGfmeszc2NlfT5QExF1wPHAGRGxEmgETomIn3T1fJKkjuly0EfEgRERlfWxlT7XZOZXM3NwZg4FzgPuz8xPdfV8kqSOafOum4j4KTAeqIuIVcAMoAYgM78PTAamRcQWYBNwXmZmt1UsSeqQ6I2Z3NDQkEuWLOnpMiRptxERSzOzoaU2vxkrSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMK1GfQRcWtEvBoRT7bSPj4i1kXE8spyTWX7ByLigYh4JiKeiogvVrt4SVLb+rZjn9uBG4A7drLP4sycuMO2LcCXM3NZROwLLI2I32Xm050rVZLUGW3O6DNzEbC2ox1n5suZuayyvgF4BjikwxVKkrqkWtfoPxIRj0XEPRExbMfGiBgK1AMPt9ZBRHw2IpZExJLVq1dXqSxJUjWCfhkwJDNHAd8F5jVvjIj+wC+ByzJzfWudZObNmdmQmQ2DBg2qQlmSJKhC0Gfm+szcWFmfD9RERB1ARNTQFPJ3ZuavunouSVLHdTnoI+LAiIjK+thKn2sq234IPJOZ13f1PJKkzmnzrpuI+CkwHqiLiFXADKAGIDO/D0wGpkXEFmATcF5mZkScAJwPPBERyyvdfa0y65ck7SJtBn1mTmmj/Qaabr/ccftDQHS+NElSNfjNWEkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVrs2gj4hbI+LViHiylfbxEbEuIpZXlmuatX08Ip6NiOciYno1C5cktU97ZvS3Ax9vY5/FmTm6snwTICL6ADcCnwCOBKZExJFdKVaS1HFtBn1mLgLWdqLvscBzmflCZr4FNAJndqIfSVIXVOsa/Uci4rGIuCcihlW2HQL8pdk+qyrbWhQRn42IJRGxZPXq1VUqS5JUjaBfBgzJzFHAd4F5le3Rwr7ZWieZeXNmNmRmw6BBg6pQliQJqhD0mbk+MzdW1ucDNRFRR9MM/gPNdh0MvNTV80mSOqbLQR8RB0ZEVNbHVvpcA/wR+GBEHBoR7wHOA37d1fNJkjqmb1s7RMRPgfFAXUSsAmYANQCZ+X1gMjAtIrYAm4DzMjOBLRHxT8B9QB/g1sx8qltGIUlqVTRlcu/S0NCQS5Ys6ekyJGm3ERFLM7OhpTa/GStJhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYWLzOzpGt4lIlYDL/Z0HR1UB7zW00XsYo55z+CYdw9DMnNQSw29Muh3RxGxJDMberqOXckx7xkc8+7PSzeSVDiDXpIKZ9BXz809XUAPcMx7Bse8m/MavSQVzhm9JBXOoJekwhn0HRAR74+I30XEf1Z+vq+V/T4eEc9GxHMRMb2F9isiIiOirvur7pqujjkirouIFRHxeETMjYj9d1nxHdCO9ywiYk6l/fGIGNPeY3urzo45Ij4QEQ9ExDMR8VREfHHXV985XXmfK+19IuLRiLhr11VdBZnp0s4F+FdgemV9OvDtFvbpAzwPHAa8B3gMOLJZ+weA+2j6QlhdT4+pu8cMfBToW1n/dkvH9/TS1ntW2ed04B4ggGOBh9t7bG9cujjmg4AxlfV9gT+VPuZm7ZcD/wbc1dPj6cjijL5jzgR+VFn/EXBWC/uMBZ7LzBcy8y2gsXLcVt8BvgLsLp+Cd2nMmfnbzNxS2e8/gMHdW26ntPWeUXl9Rzb5D2D/iDioncf2Rp0ec2a+nJnLADJzA/AMcMiuLL6TuvI+ExGDgQnALbuy6Gow6Dvm7zLzZYDKzwNa2OcQ4C/NXq+qbCMizgD+KzMf6+5Cq6hLY97BRTTNlnqb9tTf2j7tHXtv05UxbxMRQ4F64OHql1h1XR3zbJomaf/dTfV1m749XUBvExELgANbaLq6vV20sC0jol+lj492trbu0l1j3uEcVwNbgDs7Vt0u0Wb9O9mnPcf2Rl0Zc1NjRH/gl8Blmbm+irV1l06POSImAq9m5tKIGF/twrqbQb+DzDyttbaIeGXrr66VX+debWG3VTRdh99qMPAS8L+AQ4HHImLr9mURMTYz/1q1AXRCN455ax8XAhOBU7NyobOX2Wn9bezznnYc2xt1ZcxERA1NIX9nZv6qG+uspq6MeTJwRkScDtQCAyLiJ5n5qW6st3p6+kOC3WkBrmP7Dyb/tYV9+gIv0BTqWz/wGdbCfivZPT6M7dKYgY8DTwODenosOxljm+8ZTddmm39I90hH3u/etnRxzAHcAczu6XHsqjHvsM94drMPY3u8gN1pAQYCC4H/rPx8f2X7wcD8ZvudTtOdCM8DV7fS1+4S9F0aM/AcTdc8l1eW7/f0mFoZ57vqBy4FLq2sB3Bjpf0JoKEj73dvXDo7ZuAEmi55PN7sfT29p8fT3e9zsz52u6D3EQiSVDjvupGkwhn0klQ4g16SCmfQS1LhDHpJKpxBrz1GRLwTEcubLVV70mREDI2IJ6vVn1RNfjNWe5JNmTm6p4uQdjVn9NrjRcTKiPh2RDxSWf6hsn1IRCysPJd8YUT8fWX731Werf9YZTmu0lWfiPhB5Rntv42I91b2/0JEPF3pp7GHhqk9mEGvPcl7d7h0c26ztvWZORa4gaanFFJZvyMzR9L0MLY5le1zgN9n5ihgDPBUZfsHgRszcxjwOvDJyvbpQH2ln0u7Z2hS6/xmrPYYEbExM/u3sH0lcEpmvlB5WNdfM3NgRLwGHJSZb1e2v5yZdRGxGhicmX9r1sdQ4HeZ+cHK66uAmsz854i4F9gIzAPmZebGbh6qtB1n9FKTbGW9tX1a8rdm6+/wP5+BTaDp+SlHAUsjws/GtEsZ9FKTc5v9/PfK+h+A8yrr/wg8VFlfCEyDbX9DdEBrnUbEXsAHMvMBmv5oxf7Au36rkLqTMwvtSd4bEcubvb43M7feYrl3RDxM0+RnSmXbF4BbI+JKYDXw6cr2LwI3R8RnaJq5TwNebuWcfYCfRMR+ND0Z8TuZ+XqVxiO1i9fotcerXKNvyMzXeroWqTt46UaSCueMXpIK54xekgpn0EtS4Qx6SSqcQS9JhTPoJalw/x+oKx47CB2CMQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_tr_loss, label='Train loss', color='red')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss', color='blue')\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
